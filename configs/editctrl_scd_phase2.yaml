# EditCtrl + SCD Phase 2: Local + Global Context
#
# Adds GlobalContextEmbedder on top of Phase 1 checkpoint.
# Global context injects downsampled background information through cross-attention,
# helping the model maintain visual coherence between edited and unedited regions.
#
# Prerequisites:
#   - Phase 1 EditCtrl checkpoint (from editctrl_scd_phase1.yaml)
#
# Usage:
#   cd /home/johndpope/Documents/GitHub/ltx2-omnitransfer/packages/ltx-trainer
#   python -m ltx_trainer.train --config /home/johndpope/Documents/GitHub/sparse-causal-diffusion/configs/editctrl_scd_phase2.yaml

seed: 42
output_dir: /home/johndpope/Documents/GitHub/sparse-causal-diffusion/outputs/editctrl_scd_phase2

model:
  model_path: /media/2TB/ltx-models/ltx2/ltx-2-19b-dev.safetensors
  text_encoder_path: /media/2TB/ltx-models/gemma
  training_mode: lora
  # Load Phase 1 EditCtrl checkpoint
  load_checkpoint: /home/johndpope/Documents/GitHub/sparse-causal-diffusion/outputs/editctrl_scd_phase1/checkpoints

acceleration:
  mixed_precision_mode: bf16
  quantization: int8-quanto
  load_text_encoder_in_8bit: false

hardware:
  devices:
    transformer: cuda:0
    vae_encoder: cuda:0
    vae_decoder: cuda:1
    text_encoder: cuda:0
    audio_vae: cuda:0
    vocoder: cuda:0

data:
  preprocessed_data_root: /media/2TB/isometric_i2v_training
  use_cached_final_embeddings: true
  final_embeddings_dir: conditions_final
  num_dataloader_workers: 2

lora:
  rank: 64
  alpha: 64
  dropout: 0.0
  target_modules:
    - to_k
    - to_q
    - to_v
    - to_out.0

optimization:
  batch_size: 1
  gradient_accumulation_steps: 4
  learning_rate: 0.000005  # Even lower LR for phase 2 (5e-6)
  max_grad_norm: 1.0
  optimizer_type: adamw
  weight_decay: 0.0001
  scheduler_type: cosine
  scheduler_params: {}
  steps: 2000
  enable_gradient_checkpointing: true

flow_matching:
  timestep_sampling_mode: shifted_logit_normal
  timestep_sampling_params: {}

training_strategy:
  name: editctrl_scd
  encoder_layers: 32
  decoder_input_combine: token_concat
  clean_context_ratio: 0.0
  decoder_multi_batch: 1
  first_frame_conditioning_p: 0.0
  with_audio: false
  log_reconstructions: true
  reconstruction_log_interval: 100
  # EditCtrl params â€” Phase 2
  editctrl_phase: 2             # Phase 2: local + global context
  local_num_blocks: 4
  mask_dilation_latent: 2
  global_context_num_tokens: 256
  mask_min_area: 0.05
  mask_max_area: 0.6
  freeze_base_lora: true
  gradient_checkpointing_local: true

checkpoints:
  interval: 500
  keep_last_n: 3
  precision: bfloat16

wandb:
  enabled: true
  project: editctrl-scd
  entity: null
  log_validation_videos: false
  tags:
    - editctrl
    - scd
    - phase2
    - global-context

validation:
  interval: null
  skip_initial_validation: true
  prompts: []
  seed: 42
  inference_steps: 20
  guidance_scale: 4.0
  negative_prompt: "worst quality, blurry, distorted, artifacts"
  frame_rate: 25.0
  video_dims: [512, 288, 33]
  videos_per_prompt: 1
  images: null
  reference_videos: null
  generate_audio: false
  include_reference_in_output: false
  stg_mode: stg_v
  stg_scale: 1.0
  stg_blocks:
    - 29
